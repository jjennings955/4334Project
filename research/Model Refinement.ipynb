{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.sparse\n",
      "\n",
      "\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from sklearn.cross_validation import StratifiedKFold, cross_val_score\n",
      "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "tok = RegexpTokenizer(\"[a-zA-Z]+\")\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = pd.read_csv(r'./data/sorted_out_2.csv', delimiter='\\t', error_bad_lines=False)\n",
      "d.columns=[u'filename', u'sentence number', u'arg1', u'rel', u'arg2', u'arg1 start', u'arg1 end', u'rel start', u'rel end', u'arg2 start', u'arg2 end', u'conf', u'words', u'tags', u'chunks', u'a1norm', u'relnorm', u'a2norm']\n",
      "\n",
      "# Read in the labeled training data\n",
      "d2 = pd.read_csv('type2.csv - labeled.csv', delimiter=',')\n",
      "\n",
      "# Make sure the column names are properly assigned\n",
      "d2.columns = ['arg1', 'rel', 'arg2', 'label']\n",
      "\n",
      "# Fill in any unfilled label values as false\n",
      "d2['label'].fillna(0.0,inplace=True)\n",
      "\n",
      "non_foods = pd.read_csv('common_non_foods.csv', delimiter=',')\n",
      "non_foods.dropna(inplace=True)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_foods"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_foods = non_foods.reindex(index=np.random.permutation(len(non_foods)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_foods.dropna(inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "# Generate a binary feature vector for each column of our data. We do not apply stemming, or stopword removal. We do convert to lowercase.\n",
      "\n",
      "v1 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None, max_df=20000, min_df=5)\n",
      "v2 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None, min_df=1000)\n",
      "v3 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None, min_df=1000)\n",
      "\n",
      "#v1 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None)\n",
      "#v2 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None)\n",
      "#v3 = CountVectorizer(binary=True, tokenizer=lambda x: tok.tokenize(x), stop_words=None)\n",
      "\n",
      "\n",
      "normalizer = TfidfTransformer(use_idf=False, norm='l1')\n",
      "\n",
      "d.dropna(inplace=True)\n",
      "\n",
      "v1.fit(d['arg2'].values)\n",
      "v2.fit(d['rel'].values)\n",
      "v3.fit(d['arg1'].values)\n",
      "\n",
      "arg2_features = normalizer.transform(v1.transform(d2['arg2'].values))\n",
      "rel_features = normalizer.transform(v2.transform(d2['rel'].values))\n",
      "arg1_features = normalizer.transform(v3.transform(d2['arg1'].values))\n",
      "\n",
      "\n",
      "X = scipy.sparse.hstack((rel_features, arg1_features, arg2_features))\n",
      "#X = arg2_features\n",
      "\n",
      "\n",
      "non_foods.reindex(np.random.permutation(non_foods.index))\n",
      "\n",
      "a2 = normalizer.transform(v1.transform(non_foods['arg2'].values[0:3000]))\n",
      "rel = normalizer.transform(v2.transform(non_foods['rel'].values[0:3000]))\n",
      "a1 = normalizer.transform(v3.transform(non_foods['arg1'].values[0:3000]))\n",
      "\n",
      "X2 = scipy.sparse.hstack((rel, a1, a2))\n",
      "#X2 = a2\n",
      "y2 = non_foods['label'].values[0:3000]\n",
      "\n",
      "X = scipy.sparse.vstack((X,X2))\n",
      "y = d2['label'].values\n",
      "y = np.hstack((y,y2))\n",
      "\n",
      "\n",
      "#data = pd.DataFrame(rows).fillna(0).as_matrix()\n",
      "#np.random.shuffle(data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 333
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "non_foods.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 334,
       "text": [
        "200938"
       ]
      }
     ],
     "prompt_number": 334
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 346,
       "text": [
        "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "        ..., \n",
        "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 346
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 342
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "permutation = np.random.permutation(len(y))\n",
      "X = X[permutation]\n",
      "y = y[permutation]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SPLIT_POINT = 6000\n",
      "X_train = X[0:SPLIT_POINT]\n",
      "y_train = y[0:SPLIT_POINT]\n",
      "\n",
      "X_test = X[SPLIT_POINT:]\n",
      "y_test = y[SPLIT_POINT:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 348
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.svm import LinearSVC, SVC\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 349
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model1 = BernoulliNB()\n",
      "#model2 = SVC(C=1000.0, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
      "#  gamma=0.0001, kernel='rbf', max_iter=-1, probability=True,\n",
      "#  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "#modelS = SVC(C=1000.0, cache_size=200, class_weight='auto', coef0=0.0, degree=3,\n",
      "#  gamma=0.0001, kernel='rbf', max_iter=-1, probability=False,\n",
      "#  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "model3 = LogisticRegression()\n",
      "model2 = RandomForestClassifier(max_depth=12, n_estimators=10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model1.fit(X_train, y_train)\n",
      "predictions1 = model1.predict(X_test)\n",
      "\n",
      "model2.fit(X_train, y_train)\n",
      "predictions2 = model2.predict(X_test)\n",
      "\n",
      "#modelS.fit(X2, y)\n",
      "#predictionsS = modelS.predict(X2)\n",
      "\n",
      "model3.fit(X_train, y_train)\n",
      "predictions3 = model3.predict(X_test)\n",
      "\n",
      "#model4.fit(X_train, y_train)\n",
      "#predictions4 = model4.predict(X_test)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 351
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(predictions2).hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Naive Bayes\")\n",
      "print(accuracy_score(y[SPLIT_POINT:], predictions1))\n",
      "print(precision_score(y[SPLIT_POINT:], predictions1))\n",
      "print(recall_score(y[SPLIT_POINT:], predictions1))\n",
      "print(f1_score(y[SPLIT_POINT:], predictions1))\n",
      "\n",
      "print(\"Logistic Regression\")\n",
      "print(accuracy_score(y[SPLIT_POINT:], predictions3))\n",
      "print(precision_score(y[SPLIT_POINT:], predictions3))\n",
      "print(recall_score(y[SPLIT_POINT:], predictions3))\n",
      "print(f1_score(y[SPLIT_POINT:], predictions3))\n",
      "\n",
      "print(\"RF\")\n",
      "print(accuracy_score(y[SPLIT_POINT:], predictions2))\n",
      "print(precision_score(y[SPLIT_POINT:], predictions2))\n",
      "print(recall_score(y[SPLIT_POINT:], predictions2))\n",
      "print(f1_score(y[SPLIT_POINT:], predictions2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Naive Bayes\n",
        "0.912189800927\n",
        "0.959134615385\n",
        "0.815395095368\n",
        "0.881443298969\n",
        "Logistic Regression\n",
        "0.889555494955\n",
        "0.898127340824\n",
        "0.816757493188\n",
        "0.855511951481\n",
        "RF\n",
        "0.646304881374\n",
        "0.957219251337\n",
        "0.121934604905\n",
        "0.216314199396\n"
       ]
      }
     ],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "# Generate a binary feature vector for each column of our data. We do not apply stemming, or stopword removal. We do convert to lowercase.\n",
      "d.dropna(inplace=True)\n",
      "\n",
      "arg2_features = normalizer.transform(v1.transform(d['arg2'].values))\n",
      "rel_features = normalizer.transform(v2.transform(d['rel'].values))\n",
      "arg1_features = normalizer.transform(v3.transform(d['arg1'].values))\n",
      "\n",
      "\n",
      "X = scipy.sparse.hstack((rel_features, arg1_features, arg2_features))\n",
      "#X = rel_features\n",
      "\n",
      "X = X.tocsr()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d['predicted_label2'] = pd.Series(model1.predict(X), index=d.index)\n",
      "d['predicted_label_prob'] = pd.Series(model1.predict_proba(X)[:,1], index=d.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions2 = model3.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(d.query('predicted_label_prob >= 0.6'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 357,
       "text": [
        "38490"
       ]
      }
     ],
     "prompt_number": 357
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = d['predicted_label_prob'].hist()\n",
      "a.set_yscale('log')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "refinements = d.query('predicted_label_prob > 0.45 and predicted_label_prob < 0.6')\n",
      "refinements.reindex(np.random.permutation(refinements.index))\n",
      "refinements.to_csv('refinements.csv', delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confident = d.query('predicted_label_prob < 0.45 or predicted_label_prob > 0.6')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "d.to_csv('with_estimates_2.csv', delimiter=',', quoting=csv.QUOTE_ALL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confident.sort(['predicted_label2'])['predicted_label2'].hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confident[confident['predicted_label2'] == 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a2 = v1.transform(non_foods['arg2'].values)\n",
      "rel = v2.transform(non_foods['rel'].values)\n",
      "a1 = v3.transform(non_foods['arg1'].values)\n",
      "X_bad = scipy.sparse.hstack((arg2_features, rel_features, arg1_features))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = model3.predict_proba(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = model3.(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs = pd.DataFrame(l)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = probs.hist()[0,0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}