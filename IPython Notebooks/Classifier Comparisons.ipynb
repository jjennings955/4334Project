{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build Final Model used in Demonstration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.sparse\n",
      "import joblib\n",
      "\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.naive_bayes import BernoulliNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = pd.read_csv(r'./data/sorted_out_2.csv', delimiter='\\t', error_bad_lines=False, warn_bad_lines=False)\n",
      "d.columns=[u'filename', u'sentence number', u'arg1', u'rel', u'arg2', u'arg1 start', u'arg1 end', u'rel start', u'rel end', u'arg2 start', u'arg2 end', u'conf', u'words', u'tags', u'chunks', u'a1norm', u'relnorm', u'a2norm']\n",
      "\n",
      "d.dropna(inplace=True)\n",
      "\n",
      "\n",
      "# Read in the labeled training data\n",
      "d2 = pd.read_csv('./data/labeled_data.csv', delimiter=',')\n",
      "\n",
      "# Make sure the column names are properly assigned\n",
      "d2.columns = ['arg1', 'rel', 'arg2', 'label']\n",
      "\n",
      "# Fill in any unfilled label values as false\n",
      "d2['label'].fillna(0.0,inplace=True)\n",
      "#d2.dropna(inplace=True)\n",
      "\n",
      "# Read the 'common non foods' file -- this file contains data where arg2 does not contain\n",
      "# foods. It is very large and should be sampled to keep the class distribution of the training data somewhate equal\n",
      "non_foods = pd.read_csv('./data/common_non_foods.csv', delimiter=',')\n",
      "non_foods.dropna(inplace=True)\n",
      "\n",
      "# Shuffle the data so we can sample by selecting the first N elements\n",
      "non_foods = non_foods.reindex(index=np.random.permutation(len(non_foods)))\n",
      "non_foods.dropna(inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build Features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# Generate a binary feature vector for each column of our data. \n",
      "# We do not apply stemming, or stopword removal. We do convert to lowercase.\n",
      "#tok = \n",
      "#def tokenize(x):\n",
      "#    return tok.tokenize(x)\n",
      "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\")\n",
      "def tokenize(x):\n",
      "    return tokenizer.tokenize(x)\n",
      "class Vectorizer:\n",
      "    def __init__(self, vectorizers=None):\n",
      "        #self.tokenizer = RegexpTokenizer(\"[a-zA-Z]+\")\n",
      "        if vectorizers:\n",
      "            self.arg1_vectorizer, self.rel_vectorizer, self.arg2_vectorizer = vectorizers\n",
      "        else:\n",
      "            self.arg2_vectorizer = CountVectorizer(binary=True, tokenizer=tokenize, stop_words=None, max_df=20000, min_df=5, lowercase=True)\n",
      "            self.rel_vectorizer = CountVectorizer(binary=True, tokenizer=tokenize, stop_words=None, min_df=50, lowercase=True)        \n",
      "            self.arg1_vectorizer = CountVectorizer(binary=True, tokenizer=tokenize, stop_words=None, min_df=100, lowercase=True)\n",
      "    def fit(self, a1, rel, a2):\n",
      "        self.arg1_vectorizer.fit(a1)\n",
      "        self.arg2_vectorizer.fit(a2)\n",
      "        self.rel_vectorizer.fit(rel)\n",
      "    def transform(self, arg1, rel, arg2):\n",
      "        a2_feat = self.arg2_vectorizer.transform(arg2) # \"arg2\" features\n",
      "        rel_feat = self.rel_vectorizer.transform(rel) # \"rel\" features\n",
      "        a1_feat = self.arg1_vectorizer.transform(arg1) # \"arg1\" features\n",
      "        return (rel_feat, a1_feat, a2_feat)\n",
      "        \n",
      "vectorizer = Vectorizer()\n",
      "vectorizer.fit(d['arg1'].values, d['rel'].values, d['arg2'].values)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# NOTE THE ORDER: rel, arg1, arg2\n",
      "#X = scipy.sparse.hstack((rel_features, arg1_features, arg2_features))\n",
      "\n",
      "X = scipy.sparse.hstack(vectorizer.transform(d2['arg1'].values, d2['rel'].values, d2['arg2'].values))\n",
      "X2 = scipy.sparse.hstack(vectorizer.transform(non_foods['arg1'].values[0:3000], non_foods['rel'].values[0:3000], non_foods['arg1'].values[0:3000]))\n",
      "X = scipy.sparse.vstack((X,X2))\n",
      "y = np.hstack((d2['label'].values, non_foods['label'].values[0:3000]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 257
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Do a Train/Test Split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.todense()\n",
      "permutation = np.random.permutation(len(y))\n",
      "X = X[permutation]\n",
      "y = y[permutation]\n",
      "SPLIT_POINT = 6000\n",
      "X_train = X[0:SPLIT_POINT]\n",
      "y_train = y[0:SPLIT_POINT]\n",
      "\n",
      "X_test = X[SPLIT_POINT:]\n",
      "y_test = y[SPLIT_POINT:]\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Train Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import RidgeClassifierCV, Lasso, RidgeClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "ridge = RidgeClassifier()\n",
      "nb = BernoulliNB()\n",
      "dt1 = DecisionTreeClassifier(max_depth=15)\n",
      "dt2 = DecisionTreeClassifier(max_depth=20)\n",
      "dt3 = DecisionTreeClassifier()\n",
      "for modelname, model in [(\"Ridge Regression\", ridge), (\"Naive Bayes\", nb), (\"Decision Tree - 15\", dt1), (\"Decision Tree - 20\", dt2), (\"Decision Tree - 25\", dt3)]:\n",
      "    model.fit(X_train, y_train)\n",
      "    predictions1 = model.predict(X_test)\n",
      "    print(modelname)\n",
      "    print \"Accuracy :\\t%5.3f\" % accuracy_score(y_test, predictions1)\n",
      "    print \"Precision:\\t%5.3f\" % precision_score(y_test, predictions1)\n",
      "    print \"Recall   :\\t%5.3f\" % recall_score(y_test, predictions1)\n",
      "    print \"F1 Score :\\t%5.3f\" % f1_score(y_test, predictions1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Ridge Regression\n",
        "Accuracy :\t0.918\n",
        "Precision:\t0.919\n",
        "Recall   :\t0.872\n",
        "F1 Score :\t0.895\n",
        "Naive Bayes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy :\t0.904\n",
        "Precision:\t0.936\n",
        "Recall   :\t0.817\n",
        "F1 Score :\t0.873\n",
        "Decision Tree - 15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy :\t0.825\n",
        "Precision:\t0.834\n",
        "Recall   :\t0.704\n",
        "F1 Score :\t0.763\n",
        "Decision Tree - 20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy :\t0.841\n",
        "Precision:\t0.843\n",
        "Recall   :\t0.743\n",
        "F1 Score :\t0.790\n",
        "Decision Tree - 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy :\t0.864\n",
        "Precision:\t0.844\n",
        "Recall   :\t0.812\n",
        "F1 Score :\t0.828\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions1 = ridge.predict(X_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 249
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Naive Bayes\"\n",
      "print \"Accuracy :\\t%5.3f\" % accuracy_score(y_test, predictions1)\n",
      "print \"Precision:\\t%5.3f\" % precision_score(y_test, predictions1)\n",
      "print \"Recall   :\\t%5.3f\" % recall_score(y_test, predictions1)\n",
      "print \"F1 Score :\\t%5.3f\" % f1_score(y_test, predictions1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Naive Bayes\n",
        "Accuracy :\t0.980\n",
        "Precision:\t0.979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Recall   :\t0.971\n",
        "F1 Score :\t0.975\n"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Build Full Classifier (Using all data)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ridge.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 248,
       "text": [
        "RidgeClassifierCV(alphas=[0.1, 0.3, 1.0, 3.0, 9.0], class_weight=None,\n",
        "         cv=None, fit_intercept=True, normalize=False, scoring=None)"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Persist Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import joblib\n",
      "joblib.dump(vectorizer.arg1_vectorizer, 'vectorizer_arg1.pkl')\n",
      "joblib.dump(vectorizer.arg2_vectorizer, 'vectorizer_arg2.pkl')\n",
      "joblib.dump(vectorizer.rel_vectorizer, 'vectorizer_rel.pkl')\n",
      "joblib.dump(ridge, 'ridge.pkl')\n",
      "joblib.dump(nb, 'ridge.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 251,
       "text": [
        "['ridge.pkl', 'ridge.pkl_01.npy', 'ridge.pkl_02.npy', 'ridge.pkl_03.npy']"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer.fit(d['arg1'].values, d['rel'].values, d['arg2'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = vectorizer.fit(d['arg1'].values, d['rel'].values, d['arg2'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import joblib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}